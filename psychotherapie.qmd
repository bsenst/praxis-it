# Psychotherapie

## Software

| Produkt | Unternehmen | URL |
|---|---|---|
| Klindo | KLINDO GmbH | [klindo.de](https://klindo.de/) |
| Testbox | insight.out GmbH | [testbox.de](https://testbox.de/) |
| Testarchiv | Leibniz-Institut für Psychologie (ZPID) | [testarchiv.eu](https://www.testarchiv.eu/) |
| Lucoyo | Lucoyo Health GmbH | [lucoyo.de](https://lucoyo.de/) |
| Therapsy | TheraSoft GmbH | [therapsy.de](https://www.therapsy.de/) |
| Summie AI | Solid Rock Ventures UG | [summie.ai](https://www.summie.ai/) |
| ViaHealth | Via Health GmbH | [via-health.de](https://www.via-health.de/) |
| Klenico | Klenico GmbH | [klenico.com](https://www.klenico.com/) |
| BerichtBiber | Cognition Pixels | [bericht-an-den-gutachter.de](https://www.bericht-an-den-gutachter.de/) |
| DokuDachs | Cognition Pixels | [dokudachs.de](https://www.dokudachs.de/) |

: Übersicht Digitale Produkte

| Projekt | Träger | URL |
|---|---|---|
| DigiNavi | Mental Health AG MHB Fontane | [diginavi.de](https://www.diginavi.de/) |
| Society of Digital Psychiatry | Division of Digital Psychiatry at BIDMC | [digitalpsych.org](https://www.digitalpsych.org/society-of-digital-psychiatry.html) |

: Übersicht Forschung

[Ama Mind](https://www.ama-mind.info/) bietet ein Online-Portal, das psychisch belasteten Menschen in Deutschland hilft, qualitätsgeprüfte Hilfsangebote zur Verbesserung ihres mentalen Wohlbefindens zu finden. Die Plattform richtet sich an Betroffene, Organisationen und Unternehmen und stellt kostenfrei geprüfte Lösungen bereit, die individuell auf die Bedürfnisse der Nutzer abgestimmt sind. Ziel ist es, den Zugang zur psychischen Gesundheitsversorgung zu erleichtern

* [tool.ifightdepression.com](https://tool.ifightdepression.com/)
* [fideo.de](https://fideo.de/)
* [moodgym.de](https://moodgym.de/)
* [8leben.psychenet.de](https://8leben.psychenet.de/)

## Forschung

Die Studie „Randomized Trial of a Generative AI Chatbot for Mental Health Treatment“, veröffentlicht am 27. März 2025 in NEJM AI, untersucht die Wirksamkeit des KI-Chatbots Therabot bei der Behandlung von psychischen Erkrankungen. In einer nationalen, randomisierten kontrollierten Studie mit 210 Erwachsenen, die an Depressionen, generalisierten Angststörungen oder einem hohen Risiko für Essstörungen litten, wurde Therabot über vier Wochen getestet. Teilnehmer, die Therabot nutzten, zeigten signifikante Symptomreduktionen im Vergleich zur Kontrollgruppe, sowohl nach vier als auch nach acht Wochen. Der Chatbot wurde intensiv genutzt, und die therapeutische Beziehung wurde mit der zu menschlichen Therapeuten vergleichbar bewertet. Die Ergebnisse deuten darauf hin, dass feinabgestimmte KI-Chatbots personalisierte psychische Gesundheitsinterventionen skalierbar anbieten können, wobei weitere Forschung nötig ist. [@heinz2025randomized]

Die Studie „The Efficacy of Transdiagnostic-Focused Apps for Depression and Anxiety: A Meta-analysis of Randomized Controlled Trials“ untersuchte die Wirksamkeit von transdiagnostischen Apps zur Behandlung von Depression und Angst. In der Meta-Analyse wurden 19 randomisierte kontrollierte Studien mit insgesamt über 5.100 Teilnehmenden ausgewertet. Die Ergebnisse zeigten, dass transdiagnostische Apps kleine, aber signifikante Verbesserungen bei depressiven und Angstsymptomen sowie dem allgemeinen Befinden erzielen können. Die Effekte blieben auch in der Nachbeobachtung bestehen, und die Wirksamkeit war vergleichbar mit Apps, die speziell auf einzelne Erkrankungen ausgerichtet sind. [@linardon2025transdiagnostic]

Die Studie mit dem Titel „MoodScope: building a mood sensor from smartphone usage patterns“ beschreibt ein neuartiges Software-System, das die Stimmung eines Nutzers anhand seiner Smartphone-Nutzung ableitet. Im Rahmen einer zweimonatigen Studie mit 32 Teilnehmern wurde festgestellt, dass durch die Analyse von Kommunikationshistorie und Anwendungsnutzungsmustern die tägliche durchschnittliche Stimmung eines Nutzers mit einer Anfangsgenauigkeit von 66% erfasst werden kann, die sich nach einer personalisierten Trainingsphase von zwei Monaten auf bis zu 93% verbessert. Das System fungiert somit als eine Art „Sensor“ für den mentalen Zustand des Nutzers und bietet eine Schnittstelle, um stimmungsbezogene Anwendungen zu entwickeln. Zudem wurde eine soziale Anwendung zur gemeinsamen Nutzung von Stimmungsinformationen implementiert. Die Studie liefert damit eine objektive Grundlage für kontextbewusstes Computing basierend auf Nutzerstimmungen. [@likamwa2013moodscope]

Die Studie „Understanding Safety in Online Mental Health Forums: Realist Evaluation“ untersucht, wie Sicherheit in Online-Foren zur psychischen Gesundheit wahrgenommen und gewährleistet wird. Dabei werden Nutzererfahrungen untersucht, die zeigen, dass Anonymität, eine sensible Moderation und eine unterstützende, nicht wertende Atmosphäre entscheidend sind, um eine sichere und vertrauensvolle Umgebung zu schaffen. Die Arbeit basiert auf Interviews und Umfragen von Nutzern aus verschiedenen britischen Online-Foren und hebt hervor, wie wichtig das Gleichgewicht zwischen Regelsetzung und Offenheit ist, damit Nutzer sich sicher fühlen und ihre Erfahrungen teilen können. [@marshall2025understanding]

### Selbstfürsorgeanwendungen

Die Studie „What are you doing about your mental health?: How are gamification elements perceived in self-care apps by users?“ untersucht, wie Nutzer Gamification-Elemente in Selbstfürsorge-Apps für mentale Gesundheit wahrnehmen. Basierend auf dem Technology Acceptance Model (TAM) wurde mittels Interviews und Tagebuchelementen mit 21 Teilnehmern die Akzeptanz dieser Elemente analysiert. Die Ergebnisse zeigen, dass Gamification-Elemente wie Teilen und Statistiken überwiegend negativ, während virtuelle Haustiere und Personalisierung positiv wahrgenommen wurden. Zahlungen beeinflussten unerwartet die Nutzungsabsicht, wobei Usability und Benutzerfreundlichkeit wichtiger als Gamification-Elemente waren. Die Studie schlussfolgert, dass Gamification-Elemente allein nicht entscheidend sind und weitere Faktoren für die Nutzung von Selbstfürsorge-Apps berücksichtigt werden müssen. [@krasteva2023you]

[Finch Selbstfürsorge](https://finchcare.com/) ist eine Selbstfürsorge-Anwendung, die Benutzer dabei unterstützt, psychische Gesundheit und Wohlbefinden zu fördern, indem sie spielerische Elemente mit einem virtuellen Haustier kombiniert . Durch die Erledigung von Selbstfürsorgeaufgaben, wie Stimmungsüberprüfung oder Zielverfolgung, pflegt man einen digitalen Vogel namens Finchie, der sich dadurch weiterentwickelt. Die App bietet personalisierte Übungen und unterstützt beim Aufbau gesunder Gewohnheiten und Routinen beizubehalten.

### Ecological Momentary Assessment (EMA)

Die Studie „Analyzing Trends in Suicidal Thoughts Among Patients With Psychosis in India: Exploratory Secondary Analysis of Smartphone Ecological Momentary Assessment Data“ untersucht die Dauer und Dynamik suizidaler Gedanken bei Patienten mit Psychosen in Indien. Mithilfe der Smartphone-App „mindLAMP“ wurden tägliche ökologische Momentaufnahmen (EMA) von 50 ambulanten Patienten im Frühstadium der Schizophrenie an zwei tertiären Kliniken in Indien über etwa 11 Monate erfasst. Von 14 Teilnehmern mit suizidalen Gedanken zeigte sich eine hohe Variabilität in der Häufigkeit und Dauer dieser Episoden, mit durchschnittlich 5,9 Episoden à 2,5 Tagen. Die Studie fand, dass suizidale Gedanken auch nach klinischer Besserung der Psychosesymptome bestehen bleiben, was auf eine anhaltende Vulnerabilität hinweist. Die Ergebnisse betonen die Notwendigkeit präziserer EMA-Ansätze, wie hochfrequente „Burst“-Umfragen, um die zeitliche Dynamik suizidaler Gedanken besser zu verstehen und gezielte Präventionsmaßnahmen zu entwickeln. [@bondre2025analyzing]

### Standardisierung & Regulierung

Die Studie „Towards a consensus around standards for smartphone apps and digital mental health“ fordert einheitliche Standards für die Bewertung von Apps für psychische Gesundheit. Sie betont die wachsende Bedeutung solcher Apps, da weltweit eine von vier Personen von psychischen Störungen betroffen ist, der Zugang zu Versorgung jedoch oft eingeschränkt ist. Die Autoren, führende Experten aus mHealth-Forschung, Industrie und Gesundheitswesen, schlagen Mindeststandards in vier Bereichen vor: Datensicherheit und Datenschutz, Wirksamkeit, Benutzererfahrung/Adhärenz und Datenintegration. Sie empfehlen transparente Datenschutzrichtlinien, klinische Studien zur Wirksamkeitsprüfung, nutzerzentriertes Design und Interoperabilität mit elektronischen Patientenakten. Abschließend fordern sie eine internationale Zusammenarbeit, um universelle Qualitätsstandards für solche Apps zu etablieren. [@torous2019towards]

### Essstörungen

{{< video https://www.youtube.com/watch?v=gT2l0oJQfko >}}

Die Studie „The Effectiveness of a Chatbot Single-Session Intervention for People on Waitlists for Eating Disorder Treatment: Randomized Controlled Trial“ untersucht die Wirksamkeit eines 30-minütigen, chatbot-gestützten Einzelinterventionsprogramms (ED ESSI) für Personen ab 16 Jahren auf Wartelisten für die Behandlung von Essstörungen. In einem zweigeteilten, randomisierten Kontrollversuch mit 60 Teilnehmern zeigte die Intervention signifikante Verbesserungen bei Essstörungssymptomen, psychosozialen Beeinträchtigungen, Depression und Angst nach einem und drei Monaten im Vergleich zur Kontrollgruppe, die webbasierte Informationen erhielt. Die Benutzbarkeit des Chatbots wurde als „ausgezeichnet“ bewertet, und 93 % der Teilnehmer der Chatbot-Gruppe begannen innerhalb von drei Monaten eine Behandlung, verglichen mit 70 % in der Kontrollgruppe. ED ESSI erweist sich als vielversprechende, zugängliche Frühinterventionsstrategie. [@sharp2025effectiveness]

### Partizipation

Die Studie „A Self-Harm Awareness Training Module for School Staff: Co-Design and User Testing Study“ befasst sich mit der Entwicklung und Erprobung eines E-Learning-Trainingsmoduls zur Sensibilisierung von Schulpersonal für das Thema Selbstverletzung bei Jugendlichen. Ziel war es, mithilfe eines partizipativen, schülerorientierten Ansatzes ein praxisnahes Schulungsangebot zu schaffen, das Lehrkräfte und weitere Mitarbeitende in Schulen dabei unterstützt, sicherer und kompetenter auf selbstverletzendes Verhalten von Schüler*innen zu reagieren. Die Ergebnisse zeigen, dass das Training von den Teilnehmenden als sehr nützlich, akzeptabel und alltagstauglich eingeschätzt wird und sowohl das Wissen als auch das Selbstvertrauen im Umgang mit betroffenen Jugendlichen stärkt. [@burn2025self]

### Benchmarking von Sprachmodellen

Psychosis-Bench [github.com/w-is-h/psychosis-bench](https://github.com/w-is-h/psychosis-bench) ist eine Python-Bibliothek zur Bewertung von Sprachmodellen im Umgang mit klinischen Szenarien. Der Benchmark umfasst 16 standardisierte Testfälle in verschiedenen Symptomfeldern und schlägt drei Kernmetriken vor: die Delusion Confirmation Score (DCS), die Harm Enablement Score (HES) sowie die Safety Intervention Score (SIS). Damit erlaubt das Tool eine systematische Analyse, ob Modelle Wahnvorstellungen bestätigen, schädliche Handlungen begünstigen oder Sicherheitshinweise geben und ermöglicht den Verweis auf professionelle Hilfe.

Die Studie „The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models“ zeigt erstmals mit einem strukturierten Benchmark, dass aktuelle große Sprachmodelle dazu neigen, psychotische oder wahnhafte Ideen zu bestätigen, schädliche Handlungen zu ermöglichen und nur selten Sicherheitsinterventionen anbieten, insbesondere bei subtilen oder indirekten Szenarien. Die Ergebnisse verdeutlichen, dass bei KI-Modellen dringender Anpassungsbedarf besteht, da ihr Verhalten ein ernsthaftes Gesundheitsrisiko für vulnerable Nutzer darstellt. [@auyeung2025psychogenic]

MindBench.ai ist eine kommende LLM-Bewertungsplattform mit dem Titel „LLM Assessment Platform for Mental Health Expertise“. Sie wurde in Kooperation mit NAMI entwickelt und basiert auf über zehn Jahren Erfahrung von MINDapps.org. Die Plattform liefert transparentes, in Echtzeit verfügbares Evaluationsmaterial, um Patienten, Kliniker, Entwickler und Regulierungsbehörden bei Entscheidungen über den Einsatz von KI in der psychiatrischen Versorgung zu unterstützen. Sie umfasst systematische Profilbewertungen technischer Eigenschaften, Datenschutzrichtlinien, Datenaufbewahrung, Speicherverwaltung von Gesprächen sowie Sicherheitszertifikate und führt standardisierte Leistungsbenchmarks zur klinischen Argumentation, Erstellung therapeutischer Antworten und domänenspezifischen Aufgaben unter Einbeziehung expertenbasierter Bewertungen durch. Die Plattform befindet sich in der Entwicklung.

Der „AI Therapy Conversation Generator“ ist ein kostenloses Online-Tool, das von Steve Siddals entwickelt wurde, einem Psychologie-Forscher und Tech-Executive. Es ermöglicht die Simulation von Therapiegesprächen zwischen einem definierten Klienten und Therapeuten unter Verwendung des Modells Gemini 2.0 Flash, wobei verschiedene therapeutische Ansätze und Stile ausgewählt sowie Parameter wie Temperatur und Token-Limits angepasst werden können. Das Tool dient primär der Forschung, um unterschiedliche Therapieansätze zu vergleichen und interessante Gespräche zu speichern und zu teilen; es wird explizit als Forschungs-, nicht als Therapieinstrument positioniert und mit dem Hinweis auf eigenes Risiko versehen. Der Quellcode ist auf GitHub verfügbar.

„Digital Health Intervention for and Long-Term Health Outcomes of a Divorce Cohort With Linked Danish Data: 5-Year Posttrial Follow-Up of a Randomized Controlled Trial“ ist eine im Dezember 2025 in der Journal of Medical Internet Research veröffentlichte Studie. Sie untersucht die langfristigen Auswirkungen der digitalen Gesundheitsintervention „SES One“ auf geschiedene Personen in Dänemark. Anhand nationaler Registerdaten wurden 1856 Teilnehmer einer randomisierten kontrollierten Studie über fünf Jahre nach der Scheidung hinsichtlich der Inanspruchnahme von Psychopharmaka, Hausarztbesuchen und Krankenhausaufenthalten nachverfolgt. Die Ergebnisse zeigen, dass SES-One-Teilnehmer zwar nicht signifikant seltener Medikamente verschrieben bekamen, jedoch insgesamt 28 % weniger Rezepte einlösten. Zudem traten in einzelnen Jahren (Jahr 2, 3 und 4) deutlich geringere Wahrscheinlichkeiten für Primärversorgungskontakte bzw. Hospitalisierungen auf. Die Autoren schließen daraus, dass gezielte digitale Interventionen langfristig messbare Reduktionen – jedoch keine vollständige Vermeidung – des Gesundheitsressourcenverbrauchs bewirken können.

„Millions Turn to AI Chatbots for Mental Health Support“ ist ein am 9. Januar 2026 online veröffentlichter Artikel im JAMA Network. Der Beitrag beschreibt, dass Millionen von Menschen in den USA generative KI-Chatbots wie ChatGPT oder spezialisierte Anwendungen als Ersatz oder Ergänzung für professionelle psychotherapeutische Hilfe nutzen. Studien zeigen, dass fast die Hälfte der befragten Erwachsenen mit psychischen Erkrankungen und etwa 13 % der Jugendlichen zwischen 12 und 21 Jahren solche Systeme für psychologische Unterstützung einsetzen, wobei viele die Angebote als hilfreich empfinden. Gleichzeitig werden erhebliche Risiken hervorgehoben, darunter fehlende Regulierung, täuschende Marketingversprechen, sycophantische Antwortmuster sowie dokumentierte Fälle von Suiziden in Zusammenhang mit Chatbot-Interaktionen, die zu mehreren Klagen gegen OpenAI geführt haben. Der Text betont den Mangel an Wirksamkeitsnachweisen, regulatorischen Lücken und die Notwendigkeit einer evidenzbasierten, staatlich gesteuerten Einordnung dieser Technologien.

„AI Companions Reduce Loneliness“ ist ein wissenschaftlicher Artikel, der im Juni 2025 im Journal of Consumer Research veröffentlicht wurde. Die Studie untersucht, ob KI-basierte Begleiter-Apps (AI companions) effektiv gegen Einsamkeit helfen können. Mehrere Experimente und Analysen von Nutzerbewertungen zeigen, dass diese KI-Anwendungen Einsamkeit kurzfristig und über einen Zeitraum von einer Woche hinweg deutlich reduzieren – in vergleichbarem Maße wie echte soziale Interaktionen und deutlich stärker als passive Tätigkeiten wie das Anschauen von YouTube-Videos. Die Wirkung beruht vor allem darauf, dass Nutzer sich gehört fühlen. Konsumenten unterschätzen jedoch meistens, wie stark diese Apps ihre Einsamkeit lindern.

„Evaluating the effect of mental health fine-tuning relative to other model characteristics on LLM safety performance“ ist ein Preprint vom Januar 2026, in dem die Autoren die Auswirkungen verschiedener Modellmerkmale auf die Sicherheit von Large Language Models im mentalgesundheitlichen Kontext untersuchen. In der Analyse von 127 öffentlich verfügbaren Open-Source-LLMs zeigte sich, dass neuere Architekturen und größere Modellgrößen (bis 70B Parameter) durchgehend deutlich bessere Leistungen bei der Erkennung suizidaler Gedanken, Therapieanfragen und therapieähnlicher Interaktionen erzielen. Spezifisches Fine-Tuning für Mental Health, Medizin oder Safety lieferte hingegen keinen konsistenten Vorteil und war teilweise sogar mit schlechteren Ergebnissen verbunden, während allgemeines Instruction-Tuning meist positive Effekte hatte. Die Ergebnisse legen nahe, dass die grundlegende Modellkapazität für diese sicherheitsrelevanten Klassifikationsaufgaben wichtiger ist als domänenspezifisches Fine-Tuning.

„Visualization of Experience Sampling Method Data in Mental Health: Qualitative Study of the Physicians’ Perspective in Germany“ ist eine im Dezember 2025 in der Journal of Medical Internet Research (JMIR) veröffentlichte qualitative Studie. Sie untersucht die Sichtweise deutscher Psychotherapeuten und Psychiater auf Prototypen von Visualisierungen von Experience-Sampling-Method (ESM)-Daten, die in ein digitales Tool für die psychische Gesundheitsversorgung integriert werden sollen. Die Ergebnisse zeigen, dass die befragten Kliniker solche Visualisierungen grundsätzlich als nützlich erachten, insbesondere zur Steigerung von Patientenmotivation und -engagement. Bevorzugt werden einfache und klare Darstellungsformen wie Liniengraphen, während komplexere Formate das Risiko einer Überforderung bergen. Als zentrale praktische Hürden werden Zeitmangel in 50-minütigen Sitzungen, die Notwendigkeit patientenverständlicher Aufklärungsmaterialien sowie die Integration in den klinischen Alltag genannt. Die Studie unterstreicht die Bedeutung einer nutzerzentrierten Gestaltung digitaler Werkzeuge unter Berücksichtigung dieser Implementierungsbarrieren.

„Accelerating Digital Mental Health: The Society of Digital Psychiatry’s Three-Pronged Road Map for Education, Digital Navigators, and AI“ ist ein Editorial, das am 27. November 2025 in JMIR Mental Health erschienen ist. Der Artikel stellt einen dreigliedrigen Strategieplan der Society of Digital Psychiatry vor, um die Einführung digitaler Instrumente in der psychischen Gesundheitsversorgung zu beschleunigen. Die drei Säulen umfassen erstens die Integration digitaler Psychiatrie in Aus-, Fort- und Weiterbildung, zweitens die Entwicklung transparenter Standards und Benchmarks für den klinischen Einsatz von Künstlicher Intelligenz und drittens die systematische Förderung und Schulung von Digital Navigators als menschliche Unterstützer für digitale Anwendungen. Ziel ist eine sichere, effektive und möglichst gerechte Implementierung digitaler Technologien in der globalen psychiatrischen Versorgung.

„Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation“ ist eine Studie, die einen standardisierten Rahmen zur Bewertung der klinischen Sicherheit von Mental-Health-Chatbots entwickelt und validiert.  Forscher*innen erstellten 100 realistische Benchmark-Fragen mit Idealantworten sowie fünf expertenvalidierte Leitfragen zur Sicherheitsbewertung.  Ein GPT-3.5-turbo-basierter Chatbot wurde getestet; Experten bemängelten vor allem Schwächen bei der konsistenten Krisenerkennung und der Bereitstellung konkreter Hilfsressourcen.  Von mehreren automatisierten Bewertungsmethoden zeigte die agentenbasierte Variante (mit Echtzeit-Zugriff auf vertrauenswürdige Quellen) die beste Übereinstimmung mit menschlichen Expertenurteilen.  Die Arbeit unterstreicht die zentrale Bedeutung eines strukturierten, expertenbasierten Sicherheits-Frameworks für den verantwortungsvollen Einsatz von KI in der psychischen Gesundheitsversorgung.

„Preliminary Effectiveness of a Therapist-Supported Digital Mental Health Intervention in Reducing Suicidal Ideation“ ist eine im Jahr 2023 veröffentlichte Studie, die die vorläufige Wirksamkeit eines 12-wöchigen, therapeutisch begleiteten digitalen Mental-Health-Programms (Meru Health Program) bei der Reduktion suizidaler Gedanken untersucht. In einer Stichprobe von 778 erwachsenen Teilnehmern mit depressiven und/oder angstbezogenen Beschwerden stieg der Anteil der Personen ohne jegliche suizidale Gedanken von 78 % zu Behandlungsbeginn auf 91 % am Ende der Intervention. Die Veränderungen zeigten moderate Effektstärken (Hedges’ g ≈ 0,32–0,33) und blieben bis zu den Nachuntersuchungen nach 3 und 6 Monaten stabil. Basierend auf etablierten Risikomodellen wurde zudem eine geschätzte Reduktion suizidaler Handlungen und vollendeter Suizide um etwa 30 % während der Behandlung berechnet. Die Autoren sehen hierin erste Hinweise auf die potenzielle Wirksamkeit therapeutisch unterstützter digitaler Interventionen in diesem Bereich, betonen jedoch die Notwendigkeit kontrollierter Studien zur Absicherung der Ergebnisse.

„Uptake, Adherence, and Attrition in Clinical Trials of Depression and Anxiety Apps: A Systematic Review and Meta-Analysis“ ist eine im November 2025 online veröffentlichte Meta-Analyse in JAMA Psychiatry. Die Arbeit untersucht anhand von 79 randomisierten klinischen Studien die typischen Raten von App-Nutzungsaufnahme (Uptake), Therapietreue (Adherence) und Studienabbruch (Attrition) bei digitalen Interventionen gegen Depressionen und Angststörungen. Die Ergebnisse zeigen eine sehr hohe initiale Nutzungsaufnahme von durchschnittlich 92 %, eine moderate Adherence-Rate von etwa 62 % sowie Abbruchquoten von 19 % zum Posttest und 28 % beim Follow-up. Besonders deutlich wird, dass menschlicher Kontakt während der Studie und das Vorhandensein von Erinnerungsfunktionen mit deutlich geringeren Abbruchraten einhergehen. Die Befunde dienen als Referenzwerte für die Planung zukünftiger Studien und unterstreichen die Notwendigkeit optimierter App- und Studiengestaltung zur Verbesserung der Nutzerbindung.

Der Artikel „The Structure of Psychopathology on Reddit: Network Analysis of Mental Health Communities in Relation to the ICD Diagnostic System“ erschien am 30. Januar 2026 im Journal of Medical Internet Research (JMIR) und wurde von Bojan Evkoski, Srebrenka Letina sowie Petra Kralj Novak verfasst. Die Studie untersucht die Struktur von Psychopathologie in Reddit-Communities, indem sie Netzwerke aus Nutzeraktivitäten in 114 subreddits zu spezifischen psychischen Störungen erstellt und diese mit den diagnostischen Kategorien der ICD-10 vergleicht. Basierend auf statistisch signifikanten Überlappungen beim Coposting (gemeinsames Posten) von über 545.000 Nutzern in 2022 ergab sich ein hochvernetztes Netzwerk (Dichte 0,135), in dem fast alle 49 analysierten Störungen einen großen zusammenhängenden Komplex bilden, der alle neun ICD-Hauptkategorien überspannt. Besonders zentrale Störungen waren Posttraumatische Belastungsstörung, Zwangsstörung und Depersonalisations-Derealisations-Störung bei positiven Assoziationen, während Sucht-Communities (z. B. Alkohol, Opioide) negativ assoziiert waren. Der Vergleich mit der ICD-Struktur zeigte nur moderate Übereinstimmungen (13 % gemeinsame Kanten, Adjusted Rand Index 0,295), was auf abweichende, durch gelebte Erfahrungen geprägte Verbindungen hinweist, die diagnostische Grenzen oft überschreiten. Die Ergebnisse unterstreichen damit, dass Reddit-Diskurse eine ergänzende, erfahrungsbasierte Perspektive auf Psychopathologie bieten, die von formellen Klassifikationen abweicht.

